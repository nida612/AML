{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/pretrained-models/pretrained-models.pytorch-master\")\n",
    "sys.path.insert(0, \"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\n",
    "sys.path.insert(0, \"../input/iterstat2/iterative-stratification-master\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-22T14:13:03.321746Z",
     "iopub.execute_input": "2022-09-22T14:13:03.322369Z",
     "iopub.status.idle": "2022-09-22T14:13:03.329585Z",
     "shell.execute_reply.started": "2022-09-22T14:13:03.322320Z",
     "shell.execute_reply": "2022-09-22T14:13:03.328379Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import albumentations\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretrainedmodels\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_FOLDER = \"../input/bengaliai-cv19/\"\n",
    "TRAINING_FOLDS_CSV = \"train_folds.csv\"\n",
    "TESTING_CSV = \"test.csv\"\n",
    "PICKLE_FOLDER = 'image_pickles/'\n",
    "\n",
    "CONSONANT_DIACRITIC = \"consonant_diacritic\"\n",
    "VOWEL_DIACRITIC = \"vowel_diacritic\"\n",
    "GRAPHEME_ROOT = \"grapheme_root\"\n",
    "KFOLD = \"kfold\"\n",
    "IMAGE_ID = \"image_id\"\n",
    "COLUMNS = [GRAPHEME_ROOT, VOWEL_DIACRITIC, CONSONANT_DIACRITIC, IMAGE_ID, KFOLD]\n",
    "\n",
    "RESNET = 'resnet34'\n",
    "EFFNET = 'efficientnet-b3'\n",
    "BASE_MODELS = [RESNET, EFFNET]\n",
    "MODEL_MEAN = ast.literal_eval(\"(0.485, 0.456, 0.406)\")\n",
    "MODEL_STD = ast.literal_eval(\"(0.229, 0.224, 0.225)\")\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = 1\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "EPOCHS = 50\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 32\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-09-22T14:13:03.331229Z",
     "iopub.execute_input": "2022-09-22T14:13:03.332988Z",
     "iopub.status.idle": "2022-09-22T14:13:03.342486Z",
     "shell.execute_reply.started": "2022-09-22T14:13:03.332943Z",
     "shell.execute_reply": "2022-09-22T14:13:03.341632Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
    "\n",
    "        self.l0 = nn.Linear(512, 168)\n",
    "        self.l1 = nn.Linear(512, 11)\n",
    "        self.l2 = nn.Linear(512, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        l0 = self.l0(x)\n",
    "        l1 = self.l1(x)\n",
    "        l2 = self.l2(x)\n",
    "\n",
    "        return l0, l1, l2\n",
    "\n",
    "\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(EfficientNetB3, self).__init__()\n",
    "\n",
    "        # Load imagenet pre-trained model\n",
    "        self.effNet = EfficientNet.from_name('efficientnet-b3')\n",
    "\n",
    "        # Appdend output layers based on our date\n",
    "        self.fc_root = nn.Linear(in_features=1000, out_features=168)\n",
    "        self.fc_vowel = nn.Linear(in_features=1000, out_features=11)\n",
    "        self.fc_consonant = nn.Linear(in_features=1000, out_features=7)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.effNet(X)\n",
    "        output_root = self.fc_root(output)\n",
    "        output_vowel = self.fc_vowel(output)\n",
    "        output_consonant = self.fc_consonant(output)\n",
    "\n",
    "        return output_root, output_vowel, output_consonant\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, df, img_height, img_width, mean, std):\n",
    "        self.image_ids = df.image_id.values\n",
    "        self.img_arr = df.iloc[:, 1:].values\n",
    "\n",
    "        self.aug = albumentations.Compose([\n",
    "            albumentations.Resize(img_height, img_width, always_apply=True),\n",
    "            albumentations.Normalize(mean, std, always_apply=True)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.img_arr[item, :]\n",
    "        img_id = self.image_ids[item]\n",
    "\n",
    "        image = image.reshape(137, 236).astype(float)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = self.aug(image=np.array(image))[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"image_id\": img_id\n",
    "        }\n",
    "\n",
    "def test(base_model):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"using device: {device}\")\n",
    "\n",
    "    model_dispatcher = {RESNET: ResNet34, EFFNET: EfficientNetB3}\n",
    "    model = model_dispatcher[base_model](pretrained=False)\n",
    "    final_g_pred = []\n",
    "    final_v_pred = []\n",
    "    final_c_pred = []\n",
    "    final_img_ids = []\n",
    "    for fold in range(5):\n",
    "        model_path = f\"../input/trained-models/{base_model}_fold{fold}.pth\"\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Loaded model: {model_path}\")\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        c_pred, g_pred, img_ids_list, v_pred = predict_using_model(device, model)\n",
    "\n",
    "        final_g_pred.append(g_pred)\n",
    "        final_v_pred.append(v_pred)\n",
    "        final_c_pred.append(c_pred)\n",
    "        if fold == 0:\n",
    "            final_img_ids.extend(img_ids_list)\n",
    "\n",
    "    create_submission_csv(final_c_pred, final_g_pred, final_img_ids, final_v_pred)\n",
    "\n",
    "\n",
    "def predict_using_model(device, model):\n",
    "    g_pred, v_pred, c_pred = [], [], []\n",
    "    img_ids_list = []\n",
    "    for file_idx in range(4):\n",
    "        parquet_path = \"%stest_image_data_%s.parquet\" % (INPUT_FOLDER, file_idx)\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        print(f\"Loaded file: {parquet_path}\")\n",
    "\n",
    "        dataset = TestDataset(df=df,\n",
    "                              img_height=IMG_HEIGHT,\n",
    "                              img_width=IMG_WIDTH,\n",
    "                              mean=MODEL_MEAN,\n",
    "                              std=MODEL_STD)\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=TEST_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            image = d[\"image\"]\n",
    "            img_id = d[\"image_id\"]\n",
    "            image = image.to(device, dtype=torch.float)\n",
    "\n",
    "            grapheme_pred, vowel_pred, consonant_pred = model(image)\n",
    "\n",
    "            for ii, imid in enumerate(img_id):\n",
    "                g_pred.append(grapheme_pred[ii].cpu().detach().numpy())\n",
    "                v_pred.append(vowel_pred[ii].cpu().detach().numpy())\n",
    "                c_pred.append(consonant_pred[ii].cpu().detach().numpy())\n",
    "                img_ids_list.append(imid)\n",
    "    return c_pred, g_pred, img_ids_list, v_pred\n",
    "\n",
    "\n",
    "def create_submission_csv(final_c_pred, final_g_pred, final_img_ids, final_v_pred):\n",
    "    final_g = np.argmax(np.mean(np.array(final_g_pred), axis=0), axis=1)\n",
    "    final_v = np.argmax(np.mean(np.array(final_v_pred), axis=0), axis=1)\n",
    "    final_c = np.argmax(np.mean(np.array(final_c_pred), axis=0), axis=1)\n",
    "    predictions = []\n",
    "    for ii, imid in enumerate(final_img_ids):\n",
    "        predictions.append((f\"{imid}_grapheme_root\", final_g[ii]))\n",
    "        predictions.append((f\"{imid}_vowel_diacritic\", final_v[ii]))\n",
    "        predictions.append((f\"{imid}_consonant_diacritic\", final_c[ii]))\n",
    "    submission = pd.DataFrame(predictions, columns=[\"row_id\", \"target\"])\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-22T14:13:03.345286Z",
     "iopub.execute_input": "2022-09-22T14:13:03.345649Z",
     "iopub.status.idle": "2022-09-22T14:13:03.372990Z",
     "shell.execute_reply.started": "2022-09-22T14:13:03.345614Z",
     "shell.execute_reply": "2022-09-22T14:13:03.372122Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test(\"resnet34\")\n",
    "test(\"efficientnet-b3\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-09-22T14:13:03.375074Z",
     "iopub.execute_input": "2022-09-22T14:13:03.375409Z",
     "iopub.status.idle": "2022-09-22T14:13:51.893020Z",
     "shell.execute_reply.started": "2022-09-22T14:13:03.375376Z",
     "shell.execute_reply": "2022-09-22T14:13:51.891843Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": "using device: cuda:0\nLoaded model: ../input/trained-models/resnet34_fold0.pth\nLoaded file: ../input/bengaliai-cv19/test_image_data_0.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_1.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_2.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_3.parquet\nLoaded model: ../input/trained-models/resnet34_fold1.pth\nLoaded file: ../input/bengaliai-cv19/test_image_data_0.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_1.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_2.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_3.parquet\nLoaded model: ../input/trained-models/resnet34_fold2.pth\nLoaded file: ../input/bengaliai-cv19/test_image_data_0.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_1.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_2.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_3.parquet\nLoaded model: ../input/trained-models/resnet34_fold3.pth\nLoaded file: ../input/bengaliai-cv19/test_image_data_0.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_1.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_2.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_3.parquet\nLoaded model: ../input/trained-models/resnet34_fold4.pth\nLoaded file: ../input/bengaliai-cv19/test_image_data_0.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_1.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_2.parquet\nLoaded file: ../input/bengaliai-cv19/test_image_data_3.parquet\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}